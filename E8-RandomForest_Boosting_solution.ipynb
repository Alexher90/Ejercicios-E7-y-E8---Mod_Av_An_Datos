{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8\n",
    "\n",
    "## Car Price Prediction\n",
    "\n",
    "Predict if the price of a car is low or high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>State</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21490</td>\n",
       "      <td>2014</td>\n",
       "      <td>31909</td>\n",
       "      <td>MD</td>\n",
       "      <td>Nissan</td>\n",
       "      <td>MuranoAWD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21250</td>\n",
       "      <td>2016</td>\n",
       "      <td>25741</td>\n",
       "      <td>KY</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>CamaroCoupe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20925</td>\n",
       "      <td>2016</td>\n",
       "      <td>24633</td>\n",
       "      <td>SC</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Santa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14500</td>\n",
       "      <td>2012</td>\n",
       "      <td>84026</td>\n",
       "      <td>OK</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>Grand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32488</td>\n",
       "      <td>2013</td>\n",
       "      <td>22816</td>\n",
       "      <td>TN</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>Wrangler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37944</td>\n",
       "      <td>2017</td>\n",
       "      <td>5362</td>\n",
       "      <td>FL</td>\n",
       "      <td>Jeep</td>\n",
       "      <td>Wrangler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18995</td>\n",
       "      <td>2010</td>\n",
       "      <td>69431</td>\n",
       "      <td>NH</td>\n",
       "      <td>Ford</td>\n",
       "      <td>F-1504WD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28000</td>\n",
       "      <td>2015</td>\n",
       "      <td>35090</td>\n",
       "      <td>WI</td>\n",
       "      <td>Ford</td>\n",
       "      <td>ExplorerXLT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10995</td>\n",
       "      <td>2012</td>\n",
       "      <td>35100</td>\n",
       "      <td>NY</td>\n",
       "      <td>Hyundai</td>\n",
       "      <td>Sonata4dr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32991</td>\n",
       "      <td>2017</td>\n",
       "      <td>14238</td>\n",
       "      <td>TX</td>\n",
       "      <td>Kia</td>\n",
       "      <td>SorentoSX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price  Year  Mileage State       Make        Model\n",
       "0  21490  2014    31909    MD     Nissan    MuranoAWD\n",
       "1  21250  2016    25741    KY  Chevrolet  CamaroCoupe\n",
       "2  20925  2016    24633    SC    Hyundai        Santa\n",
       "3  14500  2012    84026    OK       Jeep        Grand\n",
       "4  32488  2013    22816    TN       Jeep     Wrangler\n",
       "5  37944  2017     5362    FL       Jeep     Wrangler\n",
       "6  18995  2010    69431    NH       Ford     F-1504WD\n",
       "7  28000  2015    35090    WI       Ford  ExplorerXLT\n",
       "8  10995  2012    35100    NY    Hyundai    Sonata4dr\n",
       "9  32991  2017    14238    TX        Kia    SorentoSX"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\alexh\\OneDrive\\Documents\\GitHub\\AdvancedMethodsDataAnalysisClass\\datasets\\dataTrain_carListings.zip')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "      <th>HighPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016</td>\n",
       "      <td>29242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2015</td>\n",
       "      <td>26465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2012</td>\n",
       "      <td>46739</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2017</td>\n",
       "      <td>41722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>2014</td>\n",
       "      <td>77669</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2017</td>\n",
       "      <td>18963</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>2017</td>\n",
       "      <td>15063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2014</td>\n",
       "      <td>46001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>2015</td>\n",
       "      <td>26609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>2012</td>\n",
       "      <td>87621</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL  M_CamryLE  \\\n",
       "15   2016    29242        0           0            0         0          1   \n",
       "47   2015    26465        0           0            0         0          1   \n",
       "85   2012    46739        0           1            0         0          0   \n",
       "141  2017    41722        0           0            0         0          0   \n",
       "226  2014    77669        0           0            0         0          0   \n",
       "244  2017    18963        0           0            0         0          0   \n",
       "258  2017    15063        0           0            0         0          1   \n",
       "333  2014    46001        0           0            0         0          1   \n",
       "366  2015    26609        0           0            0         0          0   \n",
       "452  2012    87621        0           1            0         0          0   \n",
       "\n",
       "     M_CamrySE  M_CamryXLE  HighPrice  \n",
       "15           0           0          1  \n",
       "47           0           0          1  \n",
       "85           0           0          1  \n",
       "141          1           0          1  \n",
       "226          0           1          0  \n",
       "244          0           1          1  \n",
       "258          0           0          1  \n",
       "333          0           0          0  \n",
       "366          1           0          1  \n",
       "452          0           0          0  "
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r'C:\\Users\\alexh\\OneDrive\\Documents\\GitHub\\AdvancedMethodsDataAnalysisClass\\datasets\\dataTrain_carListings.zip')\n",
    "data = data.loc[data['Model'].str.contains('Camry')].drop(['Make', 'State'], axis=1)\n",
    "data = data.join(pd.get_dummies(data['Model'], prefix='M'))\n",
    "data['HighPrice'] = (data['Price'] > data['Price'].mean()).astype(int)\n",
    "data = data.drop(['Model', 'Price'], axis=1)\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "      <th>HighPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016</td>\n",
       "      <td>29242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2015</td>\n",
       "      <td>26465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2012</td>\n",
       "      <td>46739</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2017</td>\n",
       "      <td>41722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>2014</td>\n",
       "      <td>77669</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2017</td>\n",
       "      <td>18963</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>2017</td>\n",
       "      <td>15063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2014</td>\n",
       "      <td>46001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>2015</td>\n",
       "      <td>26609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>2012</td>\n",
       "      <td>87621</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL  M_CamryLE  \\\n",
       "15   2016    29242        0           0            0         0          1   \n",
       "47   2015    26465        0           0            0         0          1   \n",
       "85   2012    46739        0           1            0         0          0   \n",
       "141  2017    41722        0           0            0         0          0   \n",
       "226  2014    77669        0           0            0         0          0   \n",
       "244  2017    18963        0           0            0         0          0   \n",
       "258  2017    15063        0           0            0         0          1   \n",
       "333  2014    46001        0           0            0         0          1   \n",
       "366  2015    26609        0           0            0         0          0   \n",
       "452  2012    87621        0           1            0         0          0   \n",
       "\n",
       "     M_CamrySE  M_CamryXLE  HighPrice  \n",
       "15           0           0          1  \n",
       "47           0           0          1  \n",
       "85           0           0          1  \n",
       "141          1           0          1  \n",
       "226          0           1          0  \n",
       "244          0           1          1  \n",
       "258          0           0          1  \n",
       "333          0           0          0  \n",
       "366          1           0          1  \n",
       "452          0           0          0  "
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13150, 10)"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['HighPrice']\n",
    "X = data.drop(['HighPrice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8.1\n",
    "\n",
    "Estimate a Decision Tree Classifier Manually using the code created in the Notebook #4\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "      <th>HighPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016</td>\n",
       "      <td>29242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2015</td>\n",
       "      <td>26465</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2012</td>\n",
       "      <td>46739</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2017</td>\n",
       "      <td>41722</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>2014</td>\n",
       "      <td>77669</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>2017</td>\n",
       "      <td>18963</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>2017</td>\n",
       "      <td>15063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>2014</td>\n",
       "      <td>46001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>2015</td>\n",
       "      <td>26609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>2012</td>\n",
       "      <td>87621</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL  M_CamryLE  \\\n",
       "15   2016    29242        0           0            0         0          1   \n",
       "47   2015    26465        0           0            0         0          1   \n",
       "85   2012    46739        0           1            0         0          0   \n",
       "141  2017    41722        0           0            0         0          0   \n",
       "226  2014    77669        0           0            0         0          0   \n",
       "244  2017    18963        0           0            0         0          0   \n",
       "258  2017    15063        0           0            0         0          1   \n",
       "333  2014    46001        0           0            0         0          1   \n",
       "366  2015    26609        0           0            0         0          0   \n",
       "452  2012    87621        0           1            0         0          0   \n",
       "\n",
       "     M_CamrySE  M_CamryXLE  HighPrice  \n",
       "15           0           0          1  \n",
       "47           0           0          1  \n",
       "85           0           0          1  \n",
       "141          1           0          1  \n",
       "226          0           1          0  \n",
       "244          0           1          1  \n",
       "258          0           0          1  \n",
       "333          0           0          0  \n",
       "366          1           0          1  \n",
       "452          0           0          0  "
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#remove rows with missing values\n",
    "data.dropna(inplace = True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow plots to appear in the notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Mileage', 'M_Camry', 'M_Camry4dr', 'M_CamryBase', 'M_CamryL',\n",
       "       'M_CamryLE', 'M_CamrySE', 'M_CamryXLE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición de las variables que se usarán para pronosticar si el vehículo es costoso o no:\n",
    "feature_cols = data.columns.drop('HighPrice')\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De definen las variables X y Y:\n",
    "X = data[feature_cols]\n",
    "y = data.HighPrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Mileage', 'M_Camry', 'M_Camry4dr', 'M_CamryBase', 'M_CamryL',\n",
       "       'M_CamryLE', 'M_CamrySE', 'M_CamryXLE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defino las cuatro variables para construir el árbol de decisión:\n",
    "max_depth = None\n",
    "num_pct = 10\n",
    "max_features = None\n",
    "min_gain=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mileage\n"
     ]
    }
   ],
   "source": [
    "#Se toma cada variable, en este caso se hace con la variable número 1. En este caso, se hará con la variable 1 (Mileage)\n",
    "#, y se partirá en 10 percentiles\n",
    "j = 1\n",
    "print(X.columns[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se divide la variable en la cantidad especificada en num_ctp\n",
    "splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / num_pct).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.00000e+00, 1.58728e+04, 2.32508e+04, 2.98747e+04, 3.56432e+04,\n",
       "       4.16580e+04, 4.83404e+04, 6.16152e+04, 8.07292e+04, 1.06371e+05])"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = np.unique(splits)\n",
    "splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se divide la base en 4\n",
    "k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_l = X.iloc[:, j] < splits[k]\n",
    "\n",
    "y_l = y.loc[filter_l]\n",
    "y_r = y.loc[~filter_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gini\n",
    "def gini(y):\n",
    "    if y.shape[0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - (y.mean()**2 + (1 - y.mean())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16054959591724627"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_l = gini(y_l)\n",
    "gini_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45962735393665444"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_r = gini(y_r)\n",
    "gini_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_impurity(X_col, y, split):\n",
    "    \"Calculate the gain of an split k on feature j\"\n",
    "    \n",
    "    filter_l = X_col < split\n",
    "    y_l = y.loc[filter_l]\n",
    "    y_r = y.loc[~filter_l]\n",
    "    \n",
    "    n_l = y_l.shape[0]\n",
    "    n_r = y_r.shape[0]\n",
    "    \n",
    "    gini_y = gini(y)\n",
    "    gini_l = gini(y_l)\n",
    "    gini_r = gini(y_r)\n",
    "    \n",
    "    gini_impurity_ = gini_y - (n_l / (n_l + n_r) * gini_l + n_r / (n_l + n_r) * gini_r)\n",
    "    \n",
    "    return gini_impurity_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1473493405041757"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini_impurity(X.iloc[:, j], y, splits[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(X, y, num_pct=10):\n",
    "    \n",
    "    features = range(X.shape[1])\n",
    "    \n",
    "    best_split = [0, 0, 0]  # j, split, gain\n",
    "    \n",
    "    # For all features\n",
    "    for j in features:\n",
    "        \n",
    "        splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / (num_pct+1)).tolist())\n",
    "        splits = np.unique(splits)[1:]\n",
    "        \n",
    "        # For all splits\n",
    "        for split in splits:\n",
    "            gain = gini_impurity(X.iloc[:, j], y, split)\n",
    "                        \n",
    "            if gain > best_split[2]:\n",
    "                best_split = [j, split, gain]\n",
    "    \n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2014.0, 0.23223870086324505)"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j, split, gain = best_split(X, y, 4)\n",
    "j, split, gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_l = X.iloc[:, j] < split\n",
    "\n",
    "y_l = y.loc[filter_l]\n",
    "y_r = y.loc[~filter_l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13150, 4169, 8981)"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape[0], y_l.shape[0], y_r.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5795437262357415, 0.07939553849844087, 0.8117136176372342)"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.mean(), y_l.mean(), y_r.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_grow(X_train, y_train, level=0, min_gain=0.001, max_depth=None, num_pct=10):\n",
    "    \n",
    "    # If only one observation\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], y_prob=0.5, level=level, split=-1, n_samples=1, gain=0)\n",
    "        return tree\n",
    "    \n",
    "    # Calculate the best split\n",
    "    j, split, gain = best_split(X_train, y_train, num_pct)\n",
    "    \n",
    "    # save tree and estimate prediction\n",
    "    y_pred = int(y_train.mean() >= 0.5) \n",
    "    y_prob = (y_train.sum() + 1.0) / (y_train.shape[0] + 2.0)  # Laplace correction\n",
    "    \n",
    "    tree = dict(y_pred=y_pred, y_prob=y_prob, level=level, split=-1, n_samples=X.shape[0], gain=gain)\n",
    "    \n",
    "    # Check stooping criteria\n",
    "    if gain < min_gain:\n",
    "        return tree\n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree   \n",
    "    \n",
    "    # No stooping criteria was meet, then continue to create the partition\n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l = X.loc[filter_l], y_train.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y_train.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "\n",
    "    # Next iteration to each split\n",
    "    \n",
    "    tree['sl'] = tree_grow(X_l, y_l, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    tree['sr'] = tree_grow(X_r, y_r, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_pred': 1,\n",
       " 'y_prob': 0.5780753517930095,\n",
       " 'level': 0,\n",
       " 'split': [1, 52187.63636363637],\n",
       " 'n_samples': 13150,\n",
       " 'gain': 0.23872134898880762,\n",
       " 'sl': {'y_pred': 1,\n",
       "  'y_prob': 0.8391583452211127,\n",
       "  'level': 1,\n",
       "  'split': -1,\n",
       "  'n_samples': 13150,\n",
       "  'gain': 0.03317687167496233},\n",
       " 'sr': {'y_pred': 0,\n",
       "  'y_prob': 0.12133499688084841,\n",
       "  'level': 1,\n",
       "  'split': -1,\n",
       "  'n_samples': 13150,\n",
       "  'gain': 0.04366470703709979}}"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_grow(X_train, y_train, level=0, min_gain=0.001, max_depth=1, num_pct=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = tree_grow(X_train, y_train, level=0, min_gain=0.001, max_depth=3, num_pct=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'y_pred': 1,\n",
       " 'y_prob': 0.5780753517930095,\n",
       " 'level': 0,\n",
       " 'split': [1, 52187.63636363637],\n",
       " 'n_samples': 13150,\n",
       " 'gain': 0.23872134898880762,\n",
       " 'sl': {'y_pred': 1,\n",
       "  'y_prob': 0.8391583452211127,\n",
       "  'level': 1,\n",
       "  'split': [0, 2014.0],\n",
       "  'n_samples': 13150,\n",
       "  'gain': 0.03317687167496233,\n",
       "  'sl': {'y_pred': 0,\n",
       "   'y_prob': 0.36828644501278773,\n",
       "   'level': 2,\n",
       "   'split': [0, 2012.0],\n",
       "   'n_samples': 13150,\n",
       "   'gain': 0.05908490521197157,\n",
       "   'sl': {'y_pred': 0,\n",
       "    'y_prob': 0.08,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 13150,\n",
       "    'gain': 0.01707452211653898},\n",
       "   'sr': {'y_pred': 0,\n",
       "    'y_prob': 0.46757679180887374,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 13150,\n",
       "    'gain': 0.0288082580453648}},\n",
       "  'sr': {'y_pred': 1,\n",
       "   'y_prob': 0.8743054224947308,\n",
       "   'level': 2,\n",
       "   'split': [0, 2015.0],\n",
       "   'n_samples': 13150,\n",
       "   'gain': 0.014933378976312917,\n",
       "   'sl': {'y_pred': 1,\n",
       "    'y_prob': 0.7348484848484849,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 13150,\n",
       "    'gain': 0.02449522073718463},\n",
       "   'sr': {'y_pred': 1,\n",
       "    'y_prob': 0.9278323162642611,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 13150,\n",
       "    'gain': 0.00788193356475253}}},\n",
       " 'sr': {'y_pred': 0,\n",
       "  'y_prob': 0.12133499688084841,\n",
       "  'level': 1,\n",
       "  'split': [0, 2014.0],\n",
       "  'n_samples': 13150,\n",
       "  'gain': 0.04366470703709979,\n",
       "  'sl': {'y_pred': 0,\n",
       "   'y_prob': 0.03787566899958831,\n",
       "   'level': 2,\n",
       "   'split': [0, 2012.0],\n",
       "   'n_samples': 13150,\n",
       "   'gain': 0.0044807442426036265,\n",
       "   'sl': {'y_pred': 0,\n",
       "    'y_prob': 0.007571345369831101,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 13150,\n",
       "    'gain': 6.140801902596027e-05},\n",
       "   'sr': {'y_pred': 0,\n",
       "    'y_prob': 0.11204481792717087,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 13150,\n",
       "    'gain': 0.008886478412295562}},\n",
       "  'sr': {'y_pred': 0,\n",
       "   'y_prob': 0.38254172015404364,\n",
       "   'level': 2,\n",
       "   'split': [0, 2015.0],\n",
       "   'n_samples': 13150,\n",
       "   'gain': 0.03220594684003969,\n",
       "   'sl': {'y_pred': 0,\n",
       "    'y_prob': 0.28994082840236685,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 13150,\n",
       "    'gain': 0.036116251499521634},\n",
       "   'sr': {'y_pred': 1,\n",
       "    'y_prob': 0.5547445255474452,\n",
       "    'level': 3,\n",
       "    'split': -1,\n",
       "    'n_samples': 13150,\n",
       "    'gain': 0.01941541162500815}}}}"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast\n",
    "def tree_predict(X, tree, proba=False):\n",
    "    \n",
    "    predicted = np.ones(X.shape[0])\n",
    "\n",
    "    # Check if final node\n",
    "    if tree['split'] == -1:\n",
    "        if not proba:\n",
    "            predicted = predicted * tree['y_pred']\n",
    "        else:\n",
    "            predicted = predicted * tree['y_prob']\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        j, split = tree['split']\n",
    "        filter_l = (X.iloc[:, j] < split)\n",
    "        X_l = X.loc[filter_l]\n",
    "        X_r = X.loc[~filter_l]\n",
    "\n",
    "        if X_l.shape[0] == 0:  # If left node is empty only continue with right\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "        elif X_r.shape[0] == 0:  # If right node is empty only continue with left\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "        else:\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "\n",
    "    return predicted    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = tree_predict(X_test, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8672811059907835"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluación del accuracy:\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred1, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la separación de 10 percentiles y un k = 4, podemos notar que el accuracy de la evaluación del árbol es de 0.86, lo cual es viable para la predicción para clasificar si un vehículo tiene un alto o un bajo costo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8.2\n",
    "\n",
    "Estimate a Bagging of 10 Decision Tree Classifiers Manually using the code created in the Notebook #5\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 10\n",
    "# set a seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "n_samples = X_train.shape[0]\n",
    "\n",
    "# create bootstrap samples (will be used to select rows from the DataFrame)\n",
    "samples = [np.random.choice(a=n_samples, size=n_samples, replace=True) for _ in range(n_estimators)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "np.random.seed(123) \n",
    "seeds = np.random.randint(1, 10000, size=n_estimators)\n",
    "\n",
    "trees = {}\n",
    "for i in range(n_estimators):\n",
    "    trees[i] = tree_grow(X_train, y_train, level=0, min_gain=0.001, max_depth=1, num_pct=10)\n",
    "    #trees[i].fit(X_train.iloc[samples[i]], y_train.iloc[samples[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>332784</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146436</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130476</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85618</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75474</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3    4    5    6    7    8    9\n",
       "332784  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "146436  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "130476  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "85618   1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "75474   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict \n",
    "y_pred_df = pd.DataFrame(index=X_test.index, columns=list(range(n_estimators)))\n",
    "for i in range(n_estimators):\n",
    "    y_pred_df.iloc[:, i] = tree_predict(X_test, trees[i])\n",
    "\n",
    "y_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332784    10.0\n",
       "146436    10.0\n",
       "130476    10.0\n",
       "85618     10.0\n",
       "75474      0.0\n",
       "330419     0.0\n",
       "205915    10.0\n",
       "2836       0.0\n",
       "250833    10.0\n",
       "126784     0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_df.sum(axis=1)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8709193245778611"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (y_pred_df.sum(axis=1) >= (n_estimators / 2)).astype(np.int)\n",
    "\n",
    "from sklearn import metrics\n",
    "metrics.f1_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8414746543778802"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8.3\n",
    "\n",
    "Implement the variable max_features on the Decision Tree Classifier created in 11.1.\n",
    "\n",
    "Compare the impact in the results by varing the parameter max_features\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def best_split_max(X, y, max_features, num_pct=10):\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    nums = range(X.shape[1])\n",
    "    features = np.random.choice(a=nums, size=max_features, replace=False)\n",
    "    \n",
    "    best_split = [0, 0, 0]  # j, split, gain\n",
    "    \n",
    "    # For all features\n",
    "    for j in features:\n",
    "        \n",
    "        splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / (num_pct+1)).tolist())\n",
    "        splits = np.unique(splits)[1:]\n",
    "        \n",
    "        # For all splits\n",
    "        for split in splits:\n",
    "            gain = gini_impurity(X.iloc[:, j], y, split)\n",
    "                        \n",
    "            if gain > best_split[2]:\n",
    "                best_split = [j, split, gain]\n",
    "    \n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_grow_max(X, y, max_features, level=0, min_gain=0.001, max_depth=None, num_pct=10):\n",
    "    \n",
    "    # If only one observation\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], y_prob=0.5, level=level, split=-1, n_samples=1, gain=0)\n",
    "        return tree\n",
    "    \n",
    "    # Calculate the best split\n",
    "    j, split, gain = best_split_max(X, y, max_features, num_pct)\n",
    "    \n",
    "    # save tree and estimate prediction\n",
    "    y_pred = int(y.mean() >= 0.5) \n",
    "    y_prob = (y.sum() + 1.0) / (y.shape[0] + 2.0)  # Laplace correction\n",
    "    \n",
    "    tree = dict(y_pred=y_pred, y_prob=y_prob, level=level, split=-1, n_samples=X.shape[0], gain=gain)\n",
    "    \n",
    "    # Check stooping criteria\n",
    "    if gain < min_gain:\n",
    "        return tree\n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree   \n",
    "    \n",
    "    # No stooping criteria was meet, then continue to create the partition\n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "\n",
    "    # Next iteration to each split\n",
    "    \n",
    "    tree['sl'] = tree_grow(X_l, y_l, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    tree['sr'] = tree_grow(X_r, y_r, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_max = tree_grow_max(X_train, y_train, max_features= 3, level=0, min_gain=0.001, max_depth=10, num_pct=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_predict(X, tree, proba=False):\n",
    "    \n",
    "    predicted = np.ones(X.shape[0])\n",
    "\n",
    "    # Check if final node\n",
    "    if tree['split'] == -1:\n",
    "        if not proba:\n",
    "            predicted = predicted * tree['y_pred']\n",
    "        else:\n",
    "            predicted = predicted * tree['y_prob']\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        j, split = tree['split']\n",
    "        filter_l = (X.iloc[:, j] < split)\n",
    "        X_l = X.loc[filter_l]\n",
    "        X_r = X.loc[~filter_l]\n",
    "\n",
    "        if X_l.shape[0] == 0:  # If left node is empty only continue with right\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "        elif X_r.shape[0] == 0:  # If right node is empty only continue with left\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "        else:\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "\n",
    "    return predicted    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_max = tree_predict(X_test, tree_max, proba=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8707373271889401"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = predictions_max\n",
    "\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8.4\n",
    "\n",
    "Estimate a Bagging of 10 Decision Tree Classifiers with `max_features = log(n_features)`\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_f = 10000\n",
    "max_features = round(math.log(n_f)) #Revisar la formulación del logaritmo. Corre, pero estar seguros del valor obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_max_log = tree_grow_max(X_train, y_train, max_features= max_features, level=0, min_gain=0.001, max_depth=10, num_pct=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_log = tree_predict(X_test, tree_max_log, proba=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.876036866359447"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = y_test\n",
    "y_pred = predictions_log\n",
    "\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8.5\n",
    "\n",
    "Using sklearn, train a RandomForestClassifier\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\alexh\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "pred_fit = pd.Series(cross_val_score(clf, X_train, y_train, cv=10)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8389400921658986\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8.6\n",
    "\n",
    "Find the best parameters of the RandomForestClassifier (max_depth, max_features, n_estimators)\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning max_features:\n",
    "# list of values to try for max_features\n",
    "feature_range = range(1, len(feature_cols)+1)\n",
    "\n",
    "# list to store the average Accuracy for each value of max_features\n",
    "accuracy_scores = []\n",
    "\n",
    "# use 10-fold cross-validation with each value of max_features (WARNING: SLOW!)\n",
    "for feature in feature_range:\n",
    "    clf = RandomForestClassifier(n_estimators=200, max_features=feature, random_state=1, n_jobs=-1)\n",
    "    accuracy_scores.append(cross_val_score(clf, X, y, cv=5, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(feature_range, accuracy_scores)\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo con la gráfica anterior, podemos decir que entre más variables tomo en cuenta para la evaluación de los árboles de decisión, tendremos un índice de accuracy mayor. En este caso, lo más recomendable es tomar todas las variables de la base de datos, lo que se podría decir que el proceso de evaluación sería muy similar al de bagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_estimators:\n",
    "# list of values to try for n_estimators\n",
    "estimator_range = range(10, 400, 5)\n",
    "\n",
    "# list to store the average Accuracy for each value of n_estimators\n",
    "accuracy_scores = []\n",
    "\n",
    "# use 5-fold cross-validation with each value of n_estimators (WARNING: SLOW!)\n",
    "for estimator in estimator_range:\n",
    "    clf = RandomForestClassifier(n_estimators=estimator, random_state=1, n_jobs=-1)\n",
    "    accuracy_scores.append(cross_val_score(clf, X, y, cv=5, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(estimator_range, accuracy_scores, 'k')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo con la gráfica anterior, podemos ver el comportamiento del random forest cuando el número de árboles va de 5 en 5 hasta 400. Se puede decir que el número de árboles ideal sería de aproximadamente 10 árnoles para tener el accuracy más óptimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8.7 \n",
    "\n",
    "Using xgboost train a XGBClassifier \n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='binary:logistic', random_state=None, reg_alpha=None,\n",
       "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "              tree_method=None, validate_parameters=None, verbosity=None)"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = XGBClassifier()\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8989412897016361, 0.8790322580645161)"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics.f1_score(y_pred, y_test.values), metrics.accuracy_score(y_pred, y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8.8\n",
    "\n",
    "Using xgboost train a XGBClassifier \n",
    "\n",
    "Modify the parameters learning rate, gamma, colsample_bytree. Explain what each parameter means.\n",
    "\n",
    "Evaluate the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=0.7, gamma=7, gpu_id=None,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.4, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='binary:logistic', random_state=None, reg_alpha=None,\n",
       "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "              tree_method=None, validate_parameters=None, verbosity=None)"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = XGBClassifier(learning_rate = 0.4, gamma = 7, colsample_bytree = 0.7)\n",
    "clf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las definiciones de los parámetros son los siguientes:\n",
    "#### Learning Rate: \n",
    "Es una contracción para evitar el sobre-ajuste. Luego de cada boosting generado en el modelo, podemos obtener los pesos de nuevas características y eta contrae los pesos de las características con el fin de que el proceso de boosting sea más conservador. el rango de aplicación debe ser entre 0 y 1. \n",
    "    \n",
    "#### Gamma: \n",
    "Es la reducción mínima de pérdida requerida para hacer una mayor partición en un nodo del árbol. Entre más grande es Gamma, más conservador será el algoritmo. El rango de aplicación es desde cero.\n",
    "    \n",
    "#### Colsample_bytree:\n",
    "Es porción de submuestra de columnas cuando cuando se construye cada árbol. Las submuestras ocurren una vez por cada árbol construido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.901386748844376, 0.8820276497695853)"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "metrics.f1_score(y_pred, y_test.values), metrics.accuracy_score(y_pred, y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusión:\n",
    "Luego de la evaluación de diferentes modelos para la predicción de clasificación para saber si un vehículo es caro o no, podemos concluir que el predictor que tuvo el mejor rendimiento en cuanto al F1 Score y el Accuracy fue el XGB Classifier con sus parámetros alterados como Learning Rate, Gamma y el Colsample By Tree, los cuales podemos ver que hacen que los indices de precisión incluso sean mayores comparado con el XGB Classifier implementado sin alguna modificación de sus parámetros."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
